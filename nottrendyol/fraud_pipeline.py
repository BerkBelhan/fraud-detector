import json
import re
import os
from dotenv import load_dotenv
from eksi import get_social_sentiment_eksi
from crawl4ai_agent import Crawl4AIAgent
from akakce_scraper import scrape_prices
import google.generativeai as genai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

INPUT_COST_PER_M = 0.035
OUTPUT_COST_PER_M = 0.070
# Running total cost tracker
total_cost_usd = 0.0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper Functions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_cost(input_tokens, output_tokens):
    return round(
        (input_tokens * INPUT_COST_PER_M + output_tokens * OUTPUT_COST_PER_M) / 1_000_000,
        6
    )

def run_gemini_agent(label, prompt):

    global total_cost_usd
    
    response = model.generate_content(prompt)
    usage = response.usage_metadata

    input_tokens = usage.prompt_token_count
    output_tokens = usage.candidates_token_count
    cost = compute_cost(input_tokens, output_tokens)

    total_cost_usd += cost

    print(f"ğŸ§¾ Gemini Agent: {label}")
    print(f"   - Input Tokens: {input_tokens}")
    print(f"   - Output Tokens: {output_tokens}")
    print(f"   - Total Cost: ${cost:.6f}\n")

    return response.text

def extract_json_from_gemini_response(text):
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if not match:
        print("âŒ Could not extract JSON from Gemini response.")
        print(text)
        return None
    try:
        return json.loads(match.group(0))
    except json.JSONDecodeError as e:
        print("âŒ JSON parsing failed:", e)
        print("â†ª Extracted:", match.group(0))
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini Agent Wrappers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def evaluate_with_comments(comments):
    joined = "\n".join(comments)
    prompt = f"""
You are a scam detection agent.

You are given user comments about a seller. Your job is to **analyze whether the seller appears to be a scam** (e.g., fake products, bait-and-switch, misleading listings, no delivery).

ğŸ’¡ Important:
- Do **not** treat negative cargo/delivery delays alone as scam signals.
- If comments are mostly about shipping or delivery time, state that **the seller is likely not a scam**, but **mention the cargo problems** in your reason.

Respond in this format:
{{
  "level": "Safe" | "Suspicious" | "Likely Scam",
  "reason": "..."
}}

User comments:
\"\"\"{joined}\"\"\"
"""
    text = run_gemini_agent("evaluate_with_comments", prompt)
    return extract_json_from_gemini_response(text)

def evaluate_with_price_gap(product_price, akakce_prices):
    prompt = f"""
You are a scam detection agent.

Compare this product's price with similar listings. You're checking for suspicious pricing behaviors.

ğŸ” Guidelines:
- Only treat large price gaps as scam signals **if the seller is unknown or suspicious**.
- For **fashion items** (e.g., ÅŸort, t-shirt, hÄ±rka, kaban, sweatshirt), ignore price differences **unless**:
  - The item costs more than 10,000 TL, **and**
  - The seller has no reliable reputation.
- Focus on **unreasonably low prices**, not just high ones.

Product price: {product_price}

Other prices:
{json.dumps(akakce_prices, indent=2, ensure_ascii=False)}

Return a JSON verdict like:
{{
  "level": "Safe" | "Suspicious" | "Likely Scam",
  "reason": "..."
}}
"""
    text = run_gemini_agent("evaluate_with_price_gap", prompt)
    return extract_json_from_gemini_response(text)

def combine_verdicts(comment_verdict, price_verdict):
    prompt = f"""
You are a final fraud detection agent.

You are given:
1. A sentiment-based verdict about the seller
2. A price-based verdict about the product

ğŸ¯ Your goal is to decide if the listing is truly a scam.

âš–ï¸ Judgment Policy:
- **Give higher weight to user comments.**
- If users describe the seller as trustworthy, **do not mark as scam** even if there's a price difference.
- **Do not penalize fashion products** (like ÅŸort, kaban, elbise, sweatshirt) for price gaps unless the product is expensive (>10.000 TL) AND seller has red flags.
- If cargo/shipping delays are mentioned, **they are NOT scam indicators**.

Respond in JSON:
{{
  "final_level": "Safe" | "Suspicious" | "Likely Scam",
  "summary_reason": "..."
}}

1. User Comment Verdict:
{json.dumps(comment_verdict, indent=2, ensure_ascii=False)}

2. Price Comparison Verdict:
{json.dumps(price_verdict, indent=2, ensure_ascii=False)}

Based on both, return a final risk verdict in JSON:
{{
  "final_level": "Safe" | "Suspicious" | "Likely Scam",
  "summary_reason": "..."
}}
"""
    text = run_gemini_agent("combine_verdicts", prompt)
    return extract_json_from_gemini_response(text)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main Pipeline
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    url = input("ğŸ”— Enter product URL: ").strip()
    agent = Crawl4AIAgent(url)

    if not agent.fetch_html() or not agent.extract_visible_text():
        print("âŒ Failed to extract product info.")
        return

    print("ğŸ§  Extracting product info and search queries...")
    product_raw = agent.extract_product_info()

    data = extract_json_from_gemini_response(product_raw)
    if not data:
        return

    title = data.get("title")
    price = data.get("price")
    seller = data.get("merchant")
    akakce_query = data.get("akakce_query")
    eksi_query = data.get("eksi_query")

    print(f"\nğŸ§  Title: {title}\nğŸ’° Price: {price}\nğŸ¬ Seller: {seller}")
    print(f"ğŸ” EkÅŸi Query: {eksi_query}\nğŸ” AkakÃ§e Query: {akakce_query}\n")

    # ğŸ—£ Evaluate EkÅŸi comments
    comments = get_social_sentiment_eksi(eksi_query, limit=5)
    if comments:
        print("ğŸ—£ï¸ Evaluating EkÅŸi SÃ¶zlÃ¼k sentiment...\n")
        comment_verdict = evaluate_with_comments(comments)
    else:
        comment_verdict = {
            "level": "Unknown",
            "reason": "No user comments found on EkÅŸi SÃ¶zlÃ¼k."
        }

    # ğŸ’° Evaluate price comparison
    print("ğŸ’° Checking AkakÃ§e for price comparison...\n")
    akakce_data = scrape_prices(akakce_query, limit=5, headless=True)
    price_verdict = evaluate_with_price_gap(price, akakce_data)

    # ğŸ§  Final decision agent
    final_verdict = combine_verdicts(comment_verdict, price_verdict)

    print("\nğŸ“£ Final Scam Verdict:\n", json.dumps(final_verdict, indent=2, ensure_ascii=False))
    print(f"\nğŸ’¸ Total Gemini API Cost for this run: ${total_cost_usd:.6f}")

if __name__ == "__main__":
    main()